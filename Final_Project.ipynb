{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CRAUGUTH/nnProject/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e55DaojVMuVI"
      },
      "source": [
        "# **Training NN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PYu6ivkHzjj"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade spotipy torch pandas scikit-learn transformers librosa joblib\n",
        "\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import joblib\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dn3wNUImH1RX"
      },
      "outputs": [],
      "source": [
        "class MusicData(Dataset):\n",
        "    def __init__(self, path):\n",
        "        data = pd.read_csv(path)\n",
        "        data = data.drop(['track_id', 'artists', 'album_name', 'track_name', 'explicit'], axis=1)\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        data['track_genre'] = self.label_encoder.fit_transform(data['track_genre'])\n",
        "        self.features = data.drop(['track_genre'], axis=1).values.astype(np.float32)\n",
        "        self.labels = data['track_genre'].values.astype(np.float32)\n",
        "        self.scaler = StandardScaler()\n",
        "        self.features = self.scaler.fit_transform(self.features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx]\n",
        "        y = self.labels[idx]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VAtGym4giwan"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2mvleWfH94k"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/Junior/Semester_2/NN/Project/dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HA7BG3h0iApZ"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate model performance\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels.long()).sum().item()\n",
        "    accuracy = (total_correct / total_samples) * 100\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AZecpXpKjAFX"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = MusicData(data_path)\n",
        "save_path = \"best_model\"\n",
        "\n",
        "# Splitting the dataset\n",
        "total_size = len(dataset)\n",
        "train_set_size = int(total_size * 0.6)\n",
        "val_set_size = int(total_size * 0.2)\n",
        "test_set_size = int(total_size * 0.2)\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_set_size, val_set_size, test_set_size])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "# Model, loss, and optimizer\n",
        "input_dim = dataset.features.shape[1]\n",
        "num_classes = len(np.unique(dataset.labels))\n",
        "model = MLP(input_dim, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHjbL7unuA8B",
        "outputId": "bd1300b4-6652-4ca5-9615-e6a959206220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Validation Accuracy: 51.84210526315789%\n",
            "Epoch 2, Validation Accuracy: 60.88157894736842%\n",
            "Epoch 3, Validation Accuracy: 65.13157894736842%\n",
            "Epoch 4, Validation Accuracy: 67.81140350877193%\n",
            "Epoch 5, Validation Accuracy: 70.92105263157895%\n",
            "Epoch 6, Validation Accuracy: 71.77192982456141%\n",
            "Epoch 7, Validation Accuracy: 75.25438596491229%\n",
            "Epoch 8, Validation Accuracy: 75.46929824561404%\n",
            "Epoch 9, Validation Accuracy: 75.6140350877193%\n",
            "Epoch 10, Validation Accuracy: 77.8859649122807%\n",
            "Epoch 11, Validation Accuracy: 78.45614035087719%\n",
            "Epoch 12, Validation Accuracy: 78.49122807017544%\n",
            "Epoch 13, Validation Accuracy: 79.46052631578947%\n",
            "Epoch 14, Validation Accuracy: 79.60964912280701%\n",
            "Epoch 15, Validation Accuracy: 80.31140350877193%\n",
            "Epoch 16, Validation Accuracy: 79.99561403508771%\n",
            "Epoch 17, Validation Accuracy: 80.28947368421052%\n",
            "Epoch 18, Validation Accuracy: 80.97368421052632%\n",
            "Epoch 19, Validation Accuracy: 80.9122807017544%\n",
            "Epoch 20, Validation Accuracy: 82.58771929824562%\n",
            "Epoch 21, Validation Accuracy: 85.05263157894737%\n",
            "Epoch 22, Validation Accuracy: 85.45175438596492%\n",
            "Epoch 23, Validation Accuracy: 85.0657894736842%\n",
            "Epoch 24, Validation Accuracy: 85.1359649122807%\n",
            "Epoch 25, Validation Accuracy: 85.4342105263158%\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Adjust learning rate based on scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    val_accuracy = evaluate(model, val_loader)\n",
        "    print(f'Epoch {epoch+1}, Validation Accuracy: {val_accuracy}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g0xm6CvuSWm",
        "outputId": "bef31579-e34d-4e7b-b8bc-c53ecc7e14d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on the test set:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.39473684210527"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Final evaluation on the test set\n",
        "print(\"Evaluating on the test set:\")\n",
        "evaluate(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMZKelGlHSYO",
        "outputId": "137ec4bf-5234-4415-d6df-f2d94e426e11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Save the model and preprocessors\n",
        "torch.save(model.state_dict(), 'song_mood_classifier.pth')\n",
        "joblib.dump(dataset.label_encoder, 'label_encoder.joblib')\n",
        "joblib.dump(dataset.scaler, 'scaler.joblib')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19C115YOikRXYQDQWR5GP1cXfjArWMqmN",
      "authorship_tag": "ABX9TyMNe/ZiP7RWBKHP6CBGYm3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}