{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CRAUGUTH/nnProject/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e55DaojVMuVI"
      },
      "source": [
        "# **Training NN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PYu6ivkHzjj"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade spotipy torch pandas scikit-learn transformers librosa joblib\n",
        "\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import joblib\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dn3wNUImH1RX"
      },
      "outputs": [],
      "source": [
        "class MusicData(Dataset):\n",
        "    def __init__(self, path):\n",
        "        data = pd.read_csv(path)\n",
        "        data = data.drop(['track_id', 'artists', 'album_name', 'track_name', 'explicit'], axis=1)\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        data['track_genre'] = self.label_encoder.fit_transform(data['track_genre'])\n",
        "        self.features = data.drop(['track_genre'], axis=1).values.astype(np.float32)\n",
        "        self.labels = data['track_genre'].values.astype(np.float32)\n",
        "        self.scaler = StandardScaler()\n",
        "        self.features = self.scaler.fit_transform(self.features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx]\n",
        "        y = self.labels[idx]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VAtGym4giwan"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2mvleWfH94k"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/Junior/Semester_2/NN/Project/dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HA7BG3h0iApZ"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate model performance\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels.long()).sum().item()\n",
        "            all_predicted.extend(predicted.view(-1).tolist())\n",
        "            all_labels.extend(labels.long().view(-1).tolist())\n",
        "\n",
        "    accuracy = (total_correct / total_samples) * 100\n",
        "    f1 = f1_score(all_labels, all_predicted, average='weighted') # weighted average of the F1 score for each class\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AZecpXpKjAFX"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = MusicData(data_path)\n",
        "save_path = \"best_model\"\n",
        "\n",
        "# Splitting the dataset\n",
        "total_size = len(dataset)\n",
        "train_set_size = int(total_size * 0.6)\n",
        "val_set_size = int(total_size * 0.2)\n",
        "test_set_size = int(total_size * 0.2)\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_set_size, val_set_size, test_set_size])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "# Model, loss, and optimizer\n",
        "input_dim = dataset.features.shape[1]\n",
        "num_classes = len(np.unique(dataset.labels))\n",
        "model = MLP(input_dim, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHjbL7unuA8B",
        "outputId": "1c33ddd0-fdc6-4186-8a8e-0d8d27184c8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Accuracy: 34.255847953216374%, Validation Accuracy: 51.71491228070175%, Training F1: 0.3246306108090284, Validation F1: 0.4924904319164748\n",
            "Epoch 2, Training Accuracy: 48.80994152046784%, Validation Accuracy: 60.675438596491226%, Training F1: 0.4778365517680585, Validation F1: 0.5919158089343505\n",
            "Epoch 3, Training Accuracy: 54.94005847953216%, Validation Accuracy: 65.70614035087719%, Training F1: 0.5426320935139963, Validation F1: 0.6474221720055642\n",
            "Epoch 4, Training Accuracy: 58.88742690058479%, Validation Accuracy: 69.12719298245614%, Training F1: 0.5836065017598016, Validation F1: 0.6766011435911\n",
            "Epoch 5, Training Accuracy: 61.72222222222222%, Validation Accuracy: 72.25877192982456%, Training F1: 0.6132828444272865, Validation F1: 0.719968971204145\n",
            "Epoch 6, Training Accuracy: 63.92836257309942%, Validation Accuracy: 72.81140350877193%, Training F1: 0.6361745685747416, Validation F1: 0.7197043351032935\n",
            "Epoch 7, Training Accuracy: 65.09356725146199%, Validation Accuracy: 75.21491228070175%, Training F1: 0.6481293896136943, Validation F1: 0.7472190778578985\n",
            "Epoch 8, Training Accuracy: 66.4780701754386%, Validation Accuracy: 75.69736842105263%, Training F1: 0.6621635919454948, Validation F1: 0.7488303087340502\n",
            "Epoch 9, Training Accuracy: 67.41228070175438%, Validation Accuracy: 76.8859649122807%, Training F1: 0.6720068938149895, Validation F1: 0.7618418550706615\n",
            "Epoch 10, Training Accuracy: 68.61403508771929%, Validation Accuracy: 77.80263157894737%, Training F1: 0.6840035282676412, Validation F1: 0.7741630435935912\n",
            "Epoch 11, Training Accuracy: 69.04093567251462%, Validation Accuracy: 77.85964912280701%, Training F1: 0.6884873021946174, Validation F1: 0.7712947043894159\n",
            "Epoch 12, Training Accuracy: 69.46491228070175%, Validation Accuracy: 78.2719298245614%, Training F1: 0.6929948241128414, Validation F1: 0.7782935881276597\n",
            "Epoch 13, Training Accuracy: 70.01461988304094%, Validation Accuracy: 79.50438596491229%, Training F1: 0.6983700061239043, Validation F1: 0.7920864858614101\n",
            "Epoch 14, Training Accuracy: 70.6593567251462%, Validation Accuracy: 79.46491228070175%, Training F1: 0.7050322799752737, Validation F1: 0.7919965654831094\n",
            "Epoch 15, Training Accuracy: 71.32456140350877%, Validation Accuracy: 80.48245614035088%, Training F1: 0.7117237393171914, Validation F1: 0.8034368774096186\n",
            "Epoch 16, Training Accuracy: 71.23391812865498%, Validation Accuracy: 79.89473684210526%, Training F1: 0.710740786483351, Validation F1: 0.7965165790391388\n",
            "Epoch 17, Training Accuracy: 71.98099415204679%, Validation Accuracy: 81.38596491228071%, Training F1: 0.7183355203256522, Validation F1: 0.8127027875669827\n",
            "Epoch 18, Training Accuracy: 72.1374269005848%, Validation Accuracy: 80.80701754385964%, Training F1: 0.719959433426079, Validation F1: 0.8055274271085369\n",
            "Epoch 19, Training Accuracy: 72.43859649122807%, Validation Accuracy: 81.19298245614036%, Training F1: 0.7230670747225934, Validation F1: 0.8083608776116981\n",
            "Epoch 20, Training Accuracy: 72.85526315789474%, Validation Accuracy: 80.62719298245614%, Training F1: 0.7272153140800164, Validation F1: 0.8047762548337901\n",
            "Epoch 21, Training Accuracy: 72.93567251461988%, Validation Accuracy: 81.15350877192982%, Training F1: 0.7281239940772408, Validation F1: 0.8078354650555668\n",
            "Epoch 22, Training Accuracy: 73.37134502923976%, Validation Accuracy: 81.26754385964912%, Training F1: 0.7324008721484397, Validation F1: 0.8077026955784811\n",
            "Epoch 23, Training Accuracy: 73.65643274853801%, Validation Accuracy: 82.21929824561404%, Training F1: 0.7354064891900849, Validation F1: 0.8211648133560076\n",
            "Epoch 24, Training Accuracy: 73.51315789473685%, Validation Accuracy: 81.6842105263158%, Training F1: 0.7340324921827867, Validation F1: 0.8141856558637538\n",
            "Epoch 25, Training Accuracy: 73.97514619883042%, Validation Accuracy: 81.98245614035088%, Training F1: 0.7384516418006052, Validation F1: 0.8152581672038357\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    train_predicted = []\n",
        "    train_labels = []\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels.long()).sum().item()\n",
        "        train_predicted.extend(predicted.view(-1).tolist())\n",
        "        train_labels.extend(labels.long().view(-1).tolist())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_accuracy = (total_correct / total_samples) * 100\n",
        "    train_f1 = f1_score(train_labels, train_predicted, average='weighted')\n",
        "\n",
        "    val_accuracy, val_f1 = evaluate(model, val_loader)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Training Accuracy: {train_accuracy}%, Validation Accuracy: {val_accuracy}%, Training F1: {train_f1}, Validation F1: {val_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0g0xm6CvuSWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e5a99c-1587-4200-8093-48793a10da3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on the test set:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82.1140350877193"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Final evaluation on the test set\n",
        "print(\"Evaluating on the test set:\")\n",
        "evaluate(model, test_loader)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HMZKelGlHSYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d833dc01-c574-4537-f4c0-427c368152fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Save the model and preprocessors\n",
        "torch.save(model.state_dict(), 'song_mood_classifier.pth')\n",
        "joblib.dump(dataset.label_encoder, 'label_encoder.joblib')\n",
        "joblib.dump(dataset.scaler, 'scaler.joblib')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19C115YOikRXYQDQWR5GP1cXfjArWMqmN",
      "authorship_tag": "ABX9TyN09Yh9B/9aO0RcTaFDENOH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}