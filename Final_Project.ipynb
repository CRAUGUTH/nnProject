{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CRAUGUTH/nnProject/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e55DaojVMuVI"
      },
      "source": [
        "# **Training NN**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PYu6ivkHzjj"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade spotipy torch pandas scikit-learn transformers librosa joblib\n",
        "\n",
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import joblib\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "dn3wNUImH1RX"
      },
      "outputs": [],
      "source": [
        "class MusicData(Dataset):\n",
        "    def __init__(self, path):\n",
        "        data = pd.read_csv(path)\n",
        "        data = data.drop(['track_id', 'artists', 'album_name', 'track_name', 'explicit'], axis=1)\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        data['track_genre'] = self.label_encoder.fit_transform(data['track_genre'])\n",
        "        self.features = data.drop(['track_genre'], axis=1).values.astype(np.float32)\n",
        "        self.labels = data['track_genre'].values.astype(np.float32)\n",
        "        self.scaler = StandardScaler()\n",
        "        self.features = self.scaler.fit_transform(self.features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.features[idx]\n",
        "        y = self.labels[idx]\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "VAtGym4giwan"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2mvleWfH94k"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/Junior/Semester_2/NN/Project/dataset.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "HA7BG3h0iApZ"
      },
      "outputs": [],
      "source": [
        "# Function to evaluate model performance\n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in data_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels.long()).sum().item()\n",
        "            all_predicted.extend(predicted.view(-1).tolist())\n",
        "            all_labels.extend(labels.long().view(-1).tolist())\n",
        "\n",
        "    accuracy = (total_correct / total_samples) * 100\n",
        "    f1 = f1_score(all_labels, all_predicted, average='weighted')\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "AZecpXpKjAFX"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = MusicData(data_path)\n",
        "save_path = \"best_model\"\n",
        "\n",
        "# Splitting the dataset\n",
        "total_size = len(dataset)\n",
        "train_set_size = int(total_size * 0.6)\n",
        "val_set_size = int(total_size * 0.2)\n",
        "test_set_size = int(total_size * 0.2)\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_set_size, val_set_size, test_set_size])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "# Model, loss, and optimizer\n",
        "input_dim = dataset.features.shape[1]\n",
        "num_classes = len(np.unique(dataset.labels))\n",
        "model = MLP(input_dim, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHjbL7unuA8B"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    train_predicted = []\n",
        "    train_labels = []\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels.long()).sum().item()\n",
        "        train_predicted.extend(predicted.view(-1).tolist())\n",
        "        train_labels.extend(labels.long().view(-1).tolist())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_accuracy = (total_correct / total_samples) * 100\n",
        "    train_f1 = f1_score(train_labels, train_predicted, average='weighted')\n",
        "\n",
        "    val_accuracy, val_f1 = evaluate(model, val_loader)\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Training Accuracy: {train_accuracy}%, Validation Accuracy: {val_accuracy}%, Training F1: {train_f1}, Validation F1: {val_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "0g0xm6CvuSWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16cd6d5a-ce1f-433a-81dc-7abf2525fb64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on the test set:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86.64035087719299"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "# Final evaluation on the test set\n",
        "print(\"Evaluating on the test set:\")\n",
        "evaluate(model, test_loader)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMZKelGlHSYO"
      },
      "outputs": [],
      "source": [
        "# Save the model and preprocessors\n",
        "torch.save(model.state_dict(), 'song_mood_classifier.pth')\n",
        "joblib.dump(dataset.label_encoder, 'label_encoder.joblib')\n",
        "joblib.dump(dataset.scaler, 'scaler.joblib')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19C115YOikRXYQDQWR5GP1cXfjArWMqmN",
      "authorship_tag": "ABX9TyP4PlWVJf36CoGG43SOXge8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}